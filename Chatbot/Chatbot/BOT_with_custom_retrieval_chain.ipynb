{"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%pip install \"transformers\" \"accelerate\" \"langchain\" \"einops\"","metadata":{"id":"7rfxtbHf6U6h","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%pip install langchain\n%pip install sentence_transformers\n%pip install chromadb","metadata":{"id":"K2AeVcla3MHW","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install bitsandbytes","metadata":{"execution":{"iopub.status.busy":"2023-07-15T11:17:53.095037Z","iopub.execute_input":"2023-07-15T11:17:53.095367Z","iopub.status.idle":"2023-07-15T11:18:08.988214Z","shell.execute_reply.started":"2023-07-15T11:17:53.095337Z","shell.execute_reply":"2023-07-15T11:18:08.986962Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting bitsandbytes\n  Downloading bitsandbytes-0.40.1.post1-py3-none-any.whl (93.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.40.1.post1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"!nvidia-smi\n","metadata":{"execution":{"iopub.status.busy":"2023-07-15T11:19:31.436765Z","iopub.execute_input":"2023-07-15T11:19:31.437243Z","iopub.status.idle":"2023-07-15T11:19:32.656963Z","shell.execute_reply.started":"2023-07-15T11:19:31.437208Z","shell.execute_reply":"2023-07-15T11:19:32.655644Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Sat Jul 15 11:19:32 2023       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   41C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n|   1  Tesla T4            Off  | 00000000:00:05.0 Off |                    0 |\n| N/A   42C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\ndevice = torch.device(1)  # Choose the desired GPU, e.g., \"cuda:0\"\ntorch.cuda.set_device(device)","metadata":{"execution":{"iopub.status.busy":"2023-07-15T11:19:49.055852Z","iopub.execute_input":"2023-07-15T11:19:49.056264Z","iopub.status.idle":"2023-07-15T11:19:49.151596Z","shell.execute_reply.started":"2023-07-15T11:19:49.056230Z","shell.execute_reply":"2023-07-15T11:19:49.150633Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import pipeline\nfrom transformers import BitsAndBytesConfig\n\nquantization_config = BitsAndBytesConfig(\n   load_in_4bit=True,\n   bnb_4bit_compute_dtype=torch.bfloat16\n)\n# load model pipeline\ngenerate_text = pipeline(model=\"databricks/dolly-v2-3b\", quantization_config=quantization_config,\n                         trust_remote_code=True, device_map= \"cuda\", return_full_text=True)\n","metadata":{"id":"lntzz8R3gJH-","execution":{"iopub.status.busy":"2023-07-15T11:19:55.960753Z","iopub.execute_input":"2023-07-15T11:19:55.961158Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/819 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a112f4fb812f4b8fa239e1c846357279"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)instruct_pipeline.py:   0%|          | 0.00/9.16k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dba4ca50d6684f3fb25f31977d2b5584"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/databricks/dolly-v2-7b:\n- instruct_pipeline.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/13.8G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03168d57428146aabe4ef041b650ab39"}},"metadata":{}}]},{"cell_type":"code","source":"# Hugging Face model pipeline\nhf_pipeline = HuggingFacePipeline(pipeline=generate_text)","metadata":{"execution":{"iopub.status.busy":"2023-07-15T05:32:45.275228Z","iopub.execute_input":"2023-07-15T05:32:45.275695Z","iopub.status.idle":"2023-07-15T05:32:45.282320Z","shell.execute_reply.started":"2023-07-15T05:32:45.275656Z","shell.execute_reply":"2023-07-15T05:32:45.281092Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from langchain.vectorstores import Chroma\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom chromadb.config import Settings\nfrom langchain.llms import HuggingFacePipeline","metadata":{"id":"LkDCJ1p03FBH","execution":{"iopub.status.busy":"2023-07-15T05:29:10.423669Z","iopub.execute_input":"2023-07-15T05:29:10.424079Z","iopub.status.idle":"2023-07-15T05:29:13.191626Z","shell.execute_reply.started":"2023-07-15T05:29:10.424042Z","shell.execute_reply":"2023-07-15T05:29:13.190471Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Text Embedding Model\nembeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')","metadata":{"id":"KueUfdmN3ycd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Vector Database configurations\npersist_directory = \"/kaggle/input/vectordb/AllMini_Chroma_Tik_500\" # add path to specific vector database\nCHROMA_SETTINGS = Settings(\n        chroma_db_impl='duckdb+parquet',\n        persist_directory=persist_directory,\n        anonymized_telemetry=False\n)","metadata":{"id":"Lglk_-fY32oZ","execution":{"iopub.status.busy":"2023-07-15T05:29:52.305582Z","iopub.execute_input":"2023-07-15T05:29:52.305974Z","iopub.status.idle":"2023-07-15T05:29:52.313094Z","shell.execute_reply.started":"2023-07-15T05:29:52.305941Z","shell.execute_reply":"2023-07-15T05:29:52.311025Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Vector Database instance\ndb = Chroma(persist_directory=persist_directory, embedding_function=embeddings, client_settings=CHROMA_SETTINGS)","metadata":{"id":"ghmnNxBj35R7","execution":{"iopub.status.busy":"2023-07-15T05:30:05.574106Z","iopub.execute_input":"2023-07-15T05:30:05.574476Z","iopub.status.idle":"2023-07-15T05:30:06.948405Z","shell.execute_reply.started":"2023-07-15T05:30:05.574446Z","shell.execute_reply":"2023-07-15T05:30:06.946760Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Sample Run on VectorDB for context retrieval\nquery = \"What are the placement statistics?\"\ndocs = db.similarity_search_with_score(query)\ncontext = docs[0][0].page_content\ncontext[:]","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":237},"id":"OYbHBoRm39dq","outputId":"d4ef1cb0-7692-4751-bd4c-0c9aca189695","execution":{"iopub.status.busy":"2023-07-15T05:30:34.089849Z","iopub.execute_input":"2023-07-15T05:30:34.090240Z","iopub.status.idle":"2023-07-15T05:30:38.406057Z","shell.execute_reply.started":"2023-07-15T05:30:34.090205Z","shell.execute_reply":"2023-07-15T05:30:38.404964Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"790e44b0bb1d411d9f61a2ca409e6561"}},"metadata":{}},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"\" campus Institutes by Companies looking to add bright young placement process include Endurance International talent to their workforce. A good number of students Group, Verse Innovation Private Limited (Dailyhunt), have been recruited with attractive packages by Media.net, Morgan Stanley, OpsHub Technologies leading Companies like Microsoft, Amazon, Zomato, Pvt. Ltd. and MAQ Software. Apart from the regular Goldman Sachs, LinkedIn, Sprinklr, Flock, OYO placement activities, the Placement Cell initiated the and Phillips. The 2018-19 placement season saw process of tying up a group of current students with recruiters from various domains of industries offering Alumni of the Insititute to mentor and prepare them job profiles like Software Engineer, R&D Engineer, for the campus placement process. The Placement Business Technology Analyst, Data Scientist, Site Cell also started with assessments and interview Reliability Engineer, ASIC Design Engineer and preparation for pre-final year students to enable Business Intelligence Consultants. More than 150 Companies participated in campus placement for the batch graduating in 2018-19. The Companies them to get internships and final job offers in the companies that participate in the campus placement. . Table 5: Placement Status Placement 2018-19 B.Tech M.Tech M.Sc(IT) M.Sc(ICT)ARD M.Des(CD) Students opting for campus placement 197 Students opting out of campus placement Total 77 274 54 7 61 90 00 90 03 00 03 02 07 09 Details B.Tech M.Tech M.Sc(IT) M.Sc(ICT)ARD M.Des(CD) Total Placed 197 50 65 01 02 The average annual salary package was Rs. 10.16 camps on health awareness, education for the lakh. The highest salary package touched Rs. 39.30 girl child, harmful effects of tobacco, surveys on lakh per annum. RURAL INTERNSHIPS women's health, occupations, wages and incomes of villagers, their hardships, and so on. Some of the outcomes of these activities included possible The B.Tech 2017-18 Batch comprising 320 students,. technological solutions, namely conversion of were placed in 31 Non-Governmental Organizations paper-based records to digital using platforms such located in 10 states for Rural Internship. The as MS Office Suite and creating mobile apps. The Internship period was from 01 to 28 December, 2018. students made group-wise poster presentations that They were involved in activities such as conducting were\""},"metadata":{}}]},{"cell_type":"code","source":"# Prompt Template \nfrom langchain import PromptTemplate, LLMChain\nprompt_template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n\n{context}\n\nQuestion: {question} Explain in points.\nHelpful Answer:\"\"\"\n\n# prompt chain\nprompt_with_context = PromptTemplate(\ninput_variables=[\"question\", \"context\"],\ntemplate= prompt_template)","metadata":{"execution":{"iopub.status.busy":"2023-07-15T05:36:30.761701Z","iopub.execute_input":"2023-07-15T05:36:30.762785Z","iopub.status.idle":"2023-07-15T05:36:30.769943Z","shell.execute_reply.started":"2023-07-15T05:36:30.762749Z","shell.execute_reply":"2023-07-15T05:36:30.768456Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# LLM custom Chain for question answering \nllm_context_chain = LLMChain(llm=hf_pipeline, prompt=prompt_with_context)","metadata":{"execution":{"iopub.status.busy":"2023-07-15T05:36:31.812171Z","iopub.execute_input":"2023-07-15T05:36:31.813320Z","iopub.status.idle":"2023-07-15T05:36:31.819151Z","shell.execute_reply.started":"2023-07-15T05:36:31.813275Z","shell.execute_reply":"2023-07-15T05:36:31.817596Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"import time\nwhile True:\n        # Get the user query \n        query = input(\"\\nEnter a query: \")\n        if query == \"exit\":\n            break\n        if query.strip() == \"\":\n            continue\n\n        # Get the answer from the chain\n        start = time.time()\n        # similarity search from vectorDB to get context\n        docs = db.similarity_search_with_score(query)\n        \n        # Retrieved context.\n        context = docs[0][0].page_content\n        \n        #Prediction from LLM QA chain through question and user query.\n        res = llm_context_chain.predict(question = query,context = context)\n        end = time.time()\n\n        # Print the result\n        print(\"\\n\\n> Question:\")\n        print(query)\n        print(f\"\\n> Answer (took {round(end - start, 2)} s.):\")\n        print(res)","metadata":{"id":"4aiIjgVHQ4f_","colab":{"base_uri":"https://localhost:8080/","height":593},"outputId":"6354342e-6649-4294-c1f0-ecf8ccd280ae","execution":{"iopub.status.busy":"2023-07-15T05:36:45.389127Z","iopub.execute_input":"2023-07-15T05:36:45.389952Z","iopub.status.idle":"2023-07-15T05:40:15.323308Z","shell.execute_reply.started":"2023-07-15T05:36:45.389915Z","shell.execute_reply":"2023-07-15T05:40:15.322252Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdin","text":"\nEnter a query:  What is the B.Tech curriculum?\n"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8939ad23cc064ab2bce569ac4b54e817"}},"metadata":{}},{"name":"stdout","text":"\n\n> Question:\nWhat is the B.Tech curriculum?\n\n> Answer (took 16.73 s.):\n\nThe BTech (ICT) curriculum is as below:\n1. Compulsory foundation courses\n2. Electives (technical, science, open)\n3. Internships and BTech projects (BTP)\n\nThe BTech (ICT) curriculum is divided in to 3 categories, called \"Foundation\", \"Electives\" and \"Projects\".\nCompulsory foundation courses are required to be taken by every student in the program. These are Telecom, Information Technology, Electronics, and Communication stream.\nElectives are added to both technical and humanities and social science skills of the program. These are formed by a set of courses, which add to both the technical strength and humanities and social science skills of the program. These include, BTech project (BTP).\nA student can get specialization in BTech by choosing multiple tracks, where the electives can be in the following four formats:\n1. ICT - Courses which have components of computer systems and communication tracks\n2. Technical - Courses which provide expertise in particular track. This usually corresponds to the Electronics Engineering specialization.\n3. Science - These provide expertise in basic sciences.\n4. Open - Humanities, social sciences and management courses.\nThe content\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter a query:  What are the placement statistics?\n"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4043adfe31f84fbc81b03a2e0b9bedda"}},"metadata":{}},{"name":"stdout","text":"\n\n> Question:\nWhat are the placement statistics?\n\n> Answer (took 15.46 s.):\n\nThe following are the placement statistics:\n1. In the year 2018-19, around 197 students of the B.Tech course, signed up for campus placement.\n2. Out of the 197 students, only 50 were successfully placed with different employers.\n3. The average salary package was around Rs.10.16 lac per annum.\n4. The highest salary package was around Rs.39.30 lac.\n5. In total, there were 90 students who did not opt for campus placement.\n\nBased on the above statistics, it can be inferred that, out of the 197 students of the B.Tech course, only around 101 students were successfully placed. The rest of the 96 students, who didn't opt for campus placement, could be mostly due to a combination of the below mentioned factors:\n1. Poor communication from the company during the campus placement season.\n2. High cost of the camp.\n3. Lack of awareness about the benefits of campus placement.\n\nHence, it can be inferred that around 101 out of the 197 students who signed up for campus placement, were successfully placed during the placement season.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter a query:  Name some cse professors.\n"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3092d185c691496cafab09f6dac03cd4"}},"metadata":{}},{"name":"stdout","text":"\n\n> Question:\nName some cse professors.\n\n> Answer (took 16.78 s.):\n\nSrimanta Mandal - 7 points, Vinay Palaparthy - 7 points, Jayprakash T Lalchandani - 8 points, Archana Nigam - 9 points, Hardik Sailor - 7 points, Associate Professor - 10 points, Assistant Professor - 15 points, Professor - 25 points, Professor - 25 points, Professor - 35 points, Professor - 45 points, Professor - 55 points, Assistant Professor - 20 points, Assistant Professor - 20 points, Assistant Professor - 35 points, Assistant Professor - 30 points, Assistant Professor - 20 points, Assistant Professor - 15 points, Assistant Professor - 10 points, Assistant Professor - 5 points, Assistant Professor - 2 points, Assistant Professor - 1 point, Assistant Professor - 1 point, Assistant Professor - 1 point, Assistant Professor - 1 point, Assistant Professor - 1 point, Assistant Professor - 1 point, Assistant Professor - 1 point, Assistant Professor - 1 point, Assistant Professor - 1 point, Assistant Professor - 1 point, Assistant Professor - 1 point, Assistant Professor - 1 point, Assistant Professor - 1 point, Assistant Professor - 1 point, Assistant Professor - 1 point, Assistant Professor - 1 point, Assistant Professor - 1 point, Assistant Professor - 1 point, Assistant Professor - 1 point, Assistant Professor\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter a query:  exit\n"}]},{"cell_type":"code","source":"","metadata":{"id":"zPaS9OqgUJh8"},"execution_count":null,"outputs":[]}]}